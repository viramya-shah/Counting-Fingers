{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob, os, sys, shutil\n",
    "\n",
    "from keras_preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.models import Sequential, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryMask(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.GaussianBlur(img, (7,7), 3)\n",
    "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    ret, new = cv2.threshold(img, 25, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    return cv2.cvtColor(new, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "x0, y0, width = 10, 50, 200\n",
    "count = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "    window = cv2.flip(frame, 1) # mirror\n",
    "    cv2.rectangle(window, (x0, y0), (x0 + width,y0 + width), (0, 255, 255), 1)\n",
    "    cv2.imshow('Image', window)\n",
    "      \n",
    "    roi = window[x0 : y0 + width, y0 : x0 + width - 1]\n",
    "    roi = binaryMask(roi)\n",
    "    \n",
    "    cv2.namedWindow('ROI', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"ROI\", roi)\n",
    "    \n",
    "    cv2.imwrite('D://Data//Counting Finger//data_collection//{}_{}.png'.format(str(5), count), roi)\n",
    "    count += 1\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print (\"{} frames stored\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model that is trained on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (2, 2), input_shape = (128, 128, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.load_weights(\"./custom_data_weights_v3.hdf5\")\n",
    "\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting via webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "x0, y0, width = 10, 50, 200\n",
    "count = 0\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "    window = cv2.flip(frame, 1) # mirror\n",
    "    cv2.rectangle(window, (x0, y0), (x0 + width,y0 + width), (0, 255, 255), 1)\n",
    "    \n",
    "    roi = window[x0 : y0 + width, y0 : x0 + width - 1]\n",
    "    roi = binaryMask(roi)\n",
    "    resize_roi = np.reshape(np.array(Image.fromarray(roi).resize((128, 128))), (128, 128, 3))\n",
    "    resize_roi = resize_roi / 255\n",
    "#     print (resize_roi.shape)\n",
    "    cv2.imshow('ROI', resize_roi)    \n",
    "    predict_class = model.predict_classes(np.reshape(resize_roi, (1, 128, 128, 3)))\n",
    "    cv2.putText(window, '{}'.format(str(predict_class)), (10,450), font, 3, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Image', window)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading again and converting to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for file in glob.glob(\"D://Data//Counting Finger//data_collection//*.png\"):\n",
    "    name = os.path.basename(file)\n",
    "    \n",
    "    i += 1\n",
    "    if i%500 == 0:\n",
    "        print (i)\n",
    "    cv2.imwrite(\"D://Data//Counting Finger//data_collection_v2//{}\".format(name), cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = load_img(\n",
    "    \"D:\\\\Data\\\\Counting Finger\\\\fingers\\\\test\\\\000e7aa6-100b-4c6b-9ff0-e7a8e53e4465_5L.png\", \n",
    "    target_size = (128, 128, 3)\n",
    ")\n",
    "\n",
    "temp_arr = img_to_array(temp)\n",
    "temp_arr = np.reshape(temp_arr, (1, 128, 128, 3))\n",
    "model_loaded_saved_weight.predict_classes(temp_arr)\n",
    "\n",
    "for i in glob.glob(\"D:\\\\Data\\\\Counting Finger\\\\fingers\\\\test\\\\*.png\"):\n",
    "    temp = load_img(\n",
    "        i,\n",
    "        target_size = (128, 128, 3)\n",
    "    )\n",
    "\n",
    "    temp_arr = img_to_array(temp)\n",
    "    temp_arr = np.reshape(temp_arr, (1, 128, 128, 3))\n",
    "    print (model_loaded_saved_weight.predict_classes(temp_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model_loaded_saved_weight.layers]\n",
    "\n",
    "activation_model = Model(\n",
    "    inputs = model.input, \n",
    "    outputs = layer_outputs\n",
    ")\n",
    "\n",
    "activations = activation_model.predict(temp_arr) \n",
    "\n",
    "layer_names = []\n",
    "for layer in model_loaded_saved_weight.layers[:8]:\n",
    "    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
    "    \n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
    "    n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
    "    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
    "    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_loaded_saved_weight.layers[8:]:\n",
    "    layer_names.append(layer.name)\n",
    "    \n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
    "    n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
    "    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
    "    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
